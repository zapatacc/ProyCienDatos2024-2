{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1792ca886606664",
   "metadata": {},
   "source": [
    "# 0. Introducci√≥n a Cron y Logger en Python\n",
    "\n",
    "## 0.1. ¬øQu√© es **Cron**?\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cron\n",
    "\n",
    "La utilidad de l√≠nea de comandos **cron** es un **programador de tareas** (job scheduler) en sistemas operativos basados en `Unix`. Su funci√≥n es permitir a los usuarios, quienes mantienen y configuran entornos de software, programar trabajos (jobs), como comandos o scripts de shell, conocidos tambi√©n como **cron jobs**, para ejecutarse peri√≥dicamente en tiempos, fechas o intervalos fijos.\n",
    "\n",
    "Cron se utiliza t√≠picamente para automatizar tareas de mantenimiento o administraci√≥n del sistema. Sin embargo, su naturaleza general lo hace √∫til para otras actividades, como descargar archivos desde Internet o revisar correos electr√≥nicos a intervalos regulares. \n",
    "\n",
    "**Cron** es m√°s adecuado para tareas repetitivas.\n",
    "\n",
    "El nombre de **cron** proviene de \"Chronos\", la palabra griega para tiempo.\n",
    "\n",
    "```bash\n",
    "# * * * * * <command to execute>\n",
    "# | | | | |\n",
    "# | | | | day of the week (0‚Äì6) (Sunday to Saturday; 7 is also Sunday on some systems)\n",
    "# | | | month (1‚Äì12)             \n",
    "# | | day of the month (1‚Äì31)\n",
    "# | hour (0‚Äì23)\n",
    "# minute (0‚Äì59)\n",
    "```\n",
    "\n",
    "### Vamos a jugar\n",
    "https://crontab.guru/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dcd94c5871c6f",
   "metadata": {},
   "source": [
    "## 0.2. ¬øQu√© es **Logger** en Python?\n",
    "\n",
    "A medida que nuestros scripts se vuelven m√°s complejos, necesitamos una forma de **monitorear** lo que est√° sucediendo en ellos, especialmente cuando algo sale mal. Aqu√≠ es donde entra **logging**. \n",
    "\n",
    "`Python` tiene un m√≥dulo integrado llamado `logging` que permite registrar eventos o mensajes en diferentes niveles: \n",
    "\n",
    "- **DEBUG**: Informaci√≥n detallada, usualmente para desarrolladores.\n",
    "- **INFO**: Confirmaci√≥n de que las cosas est√°n funcionando como se esperaba.\n",
    "- **WARNING**: Algo inesperado, pero no cr√≠tico.\n",
    "- **ERROR**: Fallos debido a un problema en el programa.\n",
    "- **CRITICAL**: Error grave, usualmente detiene el programa.\n",
    "\n",
    "Para usar **logger** en un script de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf3da74964194d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 20:27:25,689 - DEBUG - Este es un mensaje de depuraci√≥n\n",
      "2024-09-24 20:27:25,691 - INFO - Este es un mensaje informativo\n",
      "2024-09-24 20:27:25,692 - WARNING - Este es una advertencia\n",
      "2024-09-24 20:27:25,692 - ERROR - Este es un mensaje de error\n",
      "2024-09-24 20:27:25,693 - CRITICAL - Este es un error cr√≠tico\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Configuraci√≥n b√°sica de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "\n",
    "# Ejemplo de c√≥mo registrar eventos\n",
    "logging.debug(\"Este es un mensaje de depuraci√≥n\")\n",
    "logging.info(\"Este es un mensaje informativo\")\n",
    "logging.warning(\"Este es una advertencia\")\n",
    "logging.error(\"Este es un mensaje de error\")\n",
    "logging.critical(\"Este es un error cr√≠tico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ee57a2a84eb1a8",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de **Logger** en Python\n",
    "\n",
    "El m√≥dulo `logging` de Python permite una gran flexibilidad para definir c√≥mo y d√≥nde se registran los mensajes. Algunas de las configuraciones m√°s comunes son:\n",
    "\n",
    "#### 1. **Nivel de Log** (`level`)\n",
    "El nivel del log define la gravedad de los mensajes que se quieren capturar. Algunos niveles de log comunes incluyen:\n",
    "- `DEBUG`: Informaci√≥n detallada, √∫til para depuraci√≥n.\n",
    "- `INFO`: Confirmaciones de que el programa est√° funcionando como se espera.\n",
    "- `WARNING`: Indica que algo inesperado sucedi√≥, pero el programa sigue funcionando.\n",
    "- `ERROR`: Se√±ala errores m√°s graves, pero que no detienen la ejecuci√≥n.\n",
    "- `CRITICAL`: Errores graves que probablemente detendr√°n el programa.\n",
    "\n",
    "Cuando configuramos un **nivel de log**, s√≥lo se capturan los mensajes de ese nivel o superiores. Por ejemplo, si establecemos el nivel en `WARNING`, se registrar√°n los mensajes `WARNING`, `ERROR` y `CRITICAL`, pero no los `DEBUG` o `INFO`.\n",
    "\n",
    "#### 2. **Formato del mensaje** (`format`)\n",
    "El formato del mensaje permite personalizar c√≥mo se muestran los logs. Algunos componentes √∫tiles en el formato son:\n",
    "- `%(asctime)s`: La fecha y hora en que se registr√≥ el mensaje.\n",
    "- `%(levelname)s`: El nivel del log (DEBUG, INFO, WARNING, etc.).\n",
    "- `%(message)s`: El mensaje que se ha registrado.\n",
    "- `%(name)s`: El nombre del logger.\n",
    "- `%(threadName)s`: El nombre del hilo desde donde se emiti√≥ el log.\n",
    "- `%(processName)s`: El nombre del proceso que emiti√≥ el log.\n",
    "\n",
    "#### 3. **Formato de fecha y hora** (`datefmt`)\n",
    "El par√°metro `datefmt` permite personalizar el formato de la fecha y hora que se incluye en los mensajes de log. Puedes usar cualquier formato de fecha y hora compatible con Python, como el que se usa en `strftime`. Esto es √∫til para ajustar el formato a las necesidades espec√≠ficas de tu aplicaci√≥n.\n",
    "\n",
    "##### C√≥digos de Formato Comunes\n",
    "\n",
    "Aqu√≠ tienes algunos c√≥digos de formato com√∫nmente utilizados que puedes usar con `strftime`:\n",
    "\n",
    "| C√≥digo | Significado                           | Ejemplo de Salida       |\n",
    "|--------|---------------------------------------|--------------------------|\n",
    "| `%Y`   | A√±o con siglo                         | `2024`                   |\n",
    "| `%y`   | A√±o sin siglo (00-99)                | `24`                     |\n",
    "| `%m`   | Mes como un decimal con ceros (01-12)| `09`                     |\n",
    "| `%B`   | Nombre completo del mes               | `Septiembre`             |\n",
    "| `%b`   | Nombre abreviado del mes              | `Sep`                    |\n",
    "| `%d`   | D√≠a del mes (01-31)                  | `24`                     |\n",
    "| `%H`   | Hora (00-23)                         | `14`                     |\n",
    "| `%I`   | Hora (01-12)                         | `02`                     |\n",
    "| `%M`   | Minuto (00-59)                       | `05`                     |\n",
    "| `%S`   | Segundo (00-59)                      | `30`                     |\n",
    "| `%p`   | AM o PM                              | `PM`                     |\n",
    "| `%A`   | Nombre completo del d√≠a de la semana | `Martes`                 |\n",
    "| `%a`   | Nombre abreviado del d√≠a de la semana | `Mar`                    |\n",
    "| `%j`   | D√≠a del a√±o (001-366)                | `267`                    |\n",
    "| `%U`   | N√∫mero de semana del a√±o (00-53)     | `39`                     |\n",
    "| `%W`   | N√∫mero de semana del a√±o (00-53), basado en lunes | `39`          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb84a8ef7326c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 20:30:56,458 - INFO - Respaldo iniciado\n",
      "2024-09-24 20:30:56,460 - ERROR - Error: La base de datos no existe\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "                           \n",
    "logging.basicConfig(\n",
    "    # filename='backup.log', \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "     datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")\n",
    "\n",
    "def hacer_respaldo():\n",
    "    try:\n",
    "        # Supongamos que aqu√≠ ocurre el proceso de respaldo\n",
    "        logger.info(\"Respaldo iniciado\")\n",
    "        # Simulaci√≥n de respaldo\n",
    "        if os.path.exists('base_de_datos.db'):\n",
    "            logger.info(\"Respaldo exitoso\")\n",
    "        else:\n",
    "            logger.error(\"Error: La base de datos no existe\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Error cr√≠tico durante el respaldo: {e}\")\n",
    "\n",
    "# Ejecutamos la funci√≥n\n",
    "hacer_respaldo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614b0b6d3b18ce7",
   "metadata": {},
   "source": [
    "Ahora s√≠, empecemos la clase de hoy\n",
    "\n",
    "# 1. Machine Learning Pipeline a.k.a Workflow Orchestration\n",
    "\n",
    "> Un pipeline de machine learning es una serie de pasos secuenciales y automatizados que se siguen para entrenar, evaluar y desplegar un modelo de machine learning. \n",
    "> El objetivo principal de un pipeline es automatizar el proceso repetitivo de transformar datos crudos en un modelo que pueda usarse en producci√≥n.\n",
    "\n",
    "    \n",
    "### Yo tratando de explicar el orden de ejecuci√≥n de las celdas de mi `jupyter-notebook`:\n",
    "\n",
    " <img style=\"display: block; margin: auto;\" src=\"./images/orchestration-meme.png\" width=\"580\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8ef3c5d729af1",
   "metadata": {},
   "source": [
    "Revisemos lo que hemos hecho hasta ahora con nuestro c√≥digo...\n",
    "1. Downloading data ----> Ingestion\n",
    "2. Transforming the data ----> Filtering, removing outliers\n",
    "3. Preparing data for ML ----> Feature Engineering\n",
    "4. Hyper-parameter tunning ----> Best params\n",
    "5. Train the final model ----> Best params\n",
    "6. Registry the final model\n",
    "\n",
    "**Problemas:**\n",
    "- Un cuaderno gigante\n",
    "- Sin muchas instrucciones\n",
    "- Poco legible para cualquier persona\n",
    "- No escalable ni mantenible\n",
    "- Podr√≠amos decir que es un `workflow`, ya que se debe ejecutar en un orden espec√≠fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_data(year, month):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def prepare_data(df):\n",
    "    ...\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    ...\n",
    "    return X, y\n",
    "\n",
    "def find_best_model(X, y):\n",
    "    ...\n",
    "    return params\n",
    "\n",
    "def train_model(X, y, params):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    df = download_data(2024,1)\n",
    "    df = prepare_data(df)\n",
    "    X, y = feature_engineering(df)\n",
    "    model_params = find_best_model(X, y)\n",
    "    model = train_model(X, y, model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b404890b7646d",
   "metadata": {},
   "source": [
    "Mucho mejor, no?\n",
    "\n",
    "Pero sigue teniendo problemas:\n",
    "- Lo podemos agendar?\n",
    "- Qu√© pasa si tengo m√∫ltiples archivos?\n",
    "- O si no lo quiero ejecutar en mi m√°quina local?\n",
    "- Qu√© pasa si una de las funciones falla? Si es solamente temporal el fallo?\n",
    "- Y si queremos notificar que ese error ocurri√≥ a alg√∫n administrador?\n",
    "\n",
    "Hay m√∫ltiples herramientas que vienen a solventar esos problemas:\n",
    "\n",
    "- [Apache Airflow](https://airflow.apache.org/)\n",
    "- [Prefect](https://www.prefect.io/)\n",
    "- [Mage](https://www.mage.ai/)\n",
    "- [Dagster](https://dagster.io/)\n",
    "- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/)\n",
    "- [Scikitlearn Pipelines](https://scikit-learn.org/stable/modules/compose.html#pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaecb1d50d0eb2",
   "metadata": {},
   "source": [
    "# 2. Prefect\n",
    "\n",
    "## 2.1. Definiciones en **Prefect**\n",
    "\n",
    "### 2.1.1. **Task (Tarea)**\n",
    "https://docs.prefect.io/3.0/develop/write-tasks\n",
    "\n",
    "En **Prefect**, una `task` es la unidad m√°s b√°sica de trabajo en un flujo de Prefect. Una `task` representa una operaci√≥n individual que se ejecuta dentro de un flujo de trabajo (`flow`). Puedes convertir cualquier funci√≥n de Python en una `task` agregando el decorador `@task`. \n",
    "\n",
    "Las tasks pueden:\n",
    "- **Tomar entradas, realizar un trabajo y devolver salidas**: Realizan operaciones con los datos que reciben y devuelven resultados.\n",
    "- **Cachear su ejecuci√≥n a trav√©s de m√∫ltiples invocaciones**: Evitar repetir c√°lculos si una task ya se ejecut√≥ anteriormente con los mismos inputs.\n",
    "- **Encapsular la l√≥gica del flujo en unidades reutilizables**: Pueden ser utilizadas en diferentes flows.\n",
    "- **Usar logging autom√°tico** para capturar detalles de ejecuci√≥n, etiquetas (tags) y estado final.\n",
    "- **Ejecutarse de forma concurrente**: Permiten paralelismo en la ejecuci√≥n de tareas.\n",
    "- **Definirse en el mismo archivo que el `flow` o importarse de m√≥dulos**.\n",
    "- **Llamarse desde `flows` u otras `tasks`**.\n",
    "\n",
    "**Ejemplo de una tarea:**\n",
    "\n",
    "```python\n",
    "from prefect import task\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d69588b800985b",
   "metadata": {},
   "source": [
    "### 2.1.2. **Flow (Flujo)**\n",
    "https://docs.prefect.io/3.0/develop/write-flows\n",
    "\n",
    "Un `flow` en **Prefect** es una colecci√≥n de `tasks` que se ejecutan de manera organizada y coordinada. \n",
    "\n",
    "Un `flow` define c√≥mo las `tasks` interact√∫an entre s√≠ y permite orquestar la ejecuci√≥n de m√∫ltiples `tasks` con reglas espec√≠ficas, como dependencias, condicionales y paralelismo. \n",
    "\n",
    "Adem√°s, un `flow` puede manejar `tasks` de manera secuencial o en paralelo, as√≠ como gestionarlas en funci√≥n de eventos externos.\n",
    "\n",
    "Los flows se definen como funciones en Python, y pueden tomar entradas, realizar tareas y devolver resultados. Cualquier funci√≥n Python puede convertirse en un flow de Prefect a√±adiendo el decorador `@flow`:\n",
    "```python\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "```\n",
    "#### Capacidades de los Flows en Prefect:\n",
    "\n",
    "Cuando una funci√≥n se convierte en un `flow`, adquiere las siguientes capacidades:\n",
    "\n",
    "- **Seguimiento autom√°tico de metadatos** sobre las ejecuciones del flujo, como el tiempo de ejecuci√≥n y el estado final.\n",
    "- **Registro de cada estado** que el flujo alcanza, lo que permite observar y actuar sobre cada transici√≥n en la ejecuci√≥n del flow.\n",
    "- **Validaci√≥n de tipos de los argumentos** de entrada como par√°metros del flujo de trabajo.\n",
    "- **Reintentos autom√°ticos** en caso de fallo, con l√≠mites y retrasos configurables.\n",
    "- **Timeouts** para evitar que los flujos de trabajo se ejecuten durante demasiado tiempo sin control.\n",
    "- **Capacidad de despliegue**, lo que expone una API para interactuar con el flow de manera remota.\n",
    "\n",
    "Los `flows` se identifican de forma √∫nica por su nombre. Puedes especificar un nombre para el `flow` utilizando el par√°metro `name`:\n",
    "\n",
    "```python\n",
    "@flow(name=\"Mi Flujo\")\n",
    "def mi_flujo() -> str:\n",
    "    return \"¬°Hola, mundo!\"\n",
    "```\n",
    "\n",
    "Si no proporcionas un nombre, Prefect usar√° el nombre de la funci√≥n del flow.\n",
    "\n",
    "#### Ejecuci√≥n de `Flows`:\n",
    "\n",
    "Una ejecuci√≥n de flow (**flow run**) es una ejecuci√≥n individual de un `flow`.\n",
    "\n",
    "Puedes ejecutar un `flow` llam√°ndolo por su nombre de funci√≥n, de la misma manera que lo har√≠as con una funci√≥n normal de `Python`. Tambi√©n puedes ejecutar un `flow` mediante:\n",
    "\n",
    "- **Programadores externos**, como `cron`, para invocar la funci√≥n del `flow`.\n",
    "- **Desplegar el flow en Prefect Cloud** o en un servidor auto-hospedado de Prefect.\n",
    "- **Iniciar una ejecuci√≥n de flow a trav√©s de un cronograma**, la interfaz de usuario de Prefect, o la API de Prefect.\n",
    "\n",
    "Sin importar c√≥mo ejecutes el `flow`, `Prefect` monitorea su ejecuci√≥n, capturando el estado para observabilidad. Adem√°s, puedes registrar una variedad de metadatos sobre las ejecuciones del flow para monitoreo, resoluci√≥n de problemas y auditor√≠a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edee0e98d84bbc0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2.1.3. Diferencias entre `Task` y `Flow`:\n",
    "\n",
    "- **Task**: Una tarea individual, peque√±a y espec√≠fica que ejecuta una operaci√≥n.\n",
    "- **Flow**: Un contenedor que organiza y coordina la ejecuci√≥n de varias tasks, permitiendo su orquestaci√≥n.\n",
    "\n",
    "### 2.1.4. Ejemplo Completo de Task y Flow en Prefect:\n",
    "\n",
    "```python\n",
    "from prefect import task, flow\n",
    "\n",
    "@task\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "\n",
    "@flow\n",
    "def mi_flujo_principal():\n",
    "    resultado = sumar(3, 4)\n",
    "    print(f\"El resultado es {resultado}\")\n",
    "\n",
    "# Ejecutar el flow\n",
    "mi_flujo_principal()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d1c873fd6836e",
   "metadata": {},
   "source": [
    "## 2.2 Uso de `Prefect`\n",
    "\n",
    "```bash\n",
    "pip install prefect\n",
    "prefect version\n",
    "```\n",
    "\n",
    "Ahora vamos a inicializar un servidor de `prefect`\n",
    "\n",
    "```bash\n",
    "prefect server start\n",
    "```\n",
    "\n",
    "Vamos a ver un `flow` sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e81b69181ae7d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:48:48.690700Z",
     "start_time": "2024-09-24T07:48:46.007790Z"
    }
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "@task(retries=4, retry_delay_seconds=1, log_prints=True)\n",
    "def fetch_cat_fact():\n",
    "    cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "    #An endpoint that is designed to fail sporadically\n",
    "    if cat_fact.status_code >= 400:\n",
    "        raise Exception()\n",
    "    print(cat_fact.text)\n",
    "\n",
    "\n",
    "@flow\n",
    "def fetch():\n",
    "    fetch_cat_fact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e522a6a8473229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T07:49:36.657027Z",
     "start_time": "2024-09-24T07:49:31.673396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.874 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'free-boobook'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.874 | \u001B[36mINFO\u001B[0m    | prefect.engine - Created flow run\u001B[35m 'free-boobook'\u001B[0m for flow\u001B[1;35m 'fetch'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.876 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/12ee3460-35e5-4aec-b0b5-ca16275bf6a8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.876 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/12ee3460-35e5-4aec-b0b5-ca16275bf6a8\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:25.942 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - Created task run 'fetch_cat_fact-ba8' for task 'fetch_cat_fact'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:25.942 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - Created task run 'fetch_cat_fact-ba8' for task 'fetch_cat_fact'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.109 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - A healthy cat has a temperature between 38 and 39 degrees Celcius.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.109 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - A healthy cat has a temperature between 38 and 39 degrees Celcius.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.114 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-ba8' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.114 | \u001B[36mINFO\u001B[0m    | Task run 'fetch_cat_fact-ba8' - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:00:28.158 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'free-boobook'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:00:28.158 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'free-boobook'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2a5180d8f6bc9",
   "metadata": {},
   "source": [
    "Ahora veamos el concepto de `subflows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f34f9a0f83186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow\n",
    "\n",
    "\n",
    "@flow(name=\"Cat fact\")\n",
    "def fetch_cat_fact():\n",
    "    \"\"\"A flow that gets a cat fact\"\"\"\n",
    "    return httpx.get(\"https://catfact.ninja/fact?max_length=140\").json()[\"fact\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Dog fact\")\n",
    "def fetch_dog_fact():\n",
    "    \"\"\"A flow that gets a dog fact\"\"\"\n",
    "    return httpx.get(\n",
    "        \"https://dogapi.dog/api/v2/facts\",\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    ).json()[\"data\"][0][\"attributes\"][\"body\"]\n",
    "\n",
    "\n",
    "@flow(name=\"Animals fact\", log_prints=True)\n",
    "def animal_facts():\n",
    "    cat_fact = fetch_cat_fact()\n",
    "    dog_fact = fetch_dog_fact()\n",
    "    print(f\"üê±: {cat_fact} \\nüê∂: {dog_fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa2d43e134d6635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.758 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Animals fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.758 | \u001B[36mINFO\u001B[0m    | prefect.engine - Created flow run\u001B[35m 'towering-antelope'\u001B[0m for flow\u001B[1;35m 'Animals fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.759 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/a79ab48a-ba66-4728-9b64-2ae2b3ab593b</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.759 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/a79ab48a-ba66-4728-9b64-2ae2b3ab593b\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.913 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'delicate-rattlesnake'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Cat fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.913 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Created subflow run\u001B[35m 'delicate-rattlesnake'\u001B[0m for flow\u001B[1;35m 'Cat fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:27.915 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/4c8c1db1-73e3-4626-bb9e-d44d2f79762f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:27.915 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/4c8c1db1-73e3-4626-bb9e-d44d2f79762f\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.261 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'delicate-rattlesnake'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.261 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'delicate-rattlesnake'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.362 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lilac-chimpanzee'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Dog fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.362 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Created subflow run\u001B[35m 'lilac-chimpanzee'\u001B[0m for flow\u001B[1;35m 'Dog fact'\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:28.364 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/runs/flow-run/d8e0e718-6ef0-4377-a618-21c18fbc62f8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:28.364 | \u001B[36mINFO\u001B[0m    | prefect.engine - View at \u001B[94mhttp://127.0.0.1:4200/runs/flow-run/d8e0e718-6ef0-4377-a618-21c18fbc62f8\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.106 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'lilac-chimpanzee'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.106 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'lilac-chimpanzee'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.108 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - üê±: Grown cats have 30 teeth. Kittens have about 26 temporary teeth, which they lose when they are about 6 months old.\n",
       "üê∂: Hyenas aren't actually dogs. They are more closely related to cats.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.108 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - üê±: Grown cats have 30 teeth. Kittens have about 26 temporary teeth, which they lose when they are about 6 months old.\n",
       "üê∂: Hyenas aren't actually dogs. They are more closely related to cats.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:02:29.139 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'towering-antelope'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:02:29.139 | \u001B[36mINFO\u001B[0m    | Flow run\u001B[35m 'towering-antelope'\u001B[0m - Finished in state \u001B[32mCompleted\u001B[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animal_facts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982db0e9319221ee",
   "metadata": {},
   "source": [
    "Ahora vamos a hacerlo para nuestro pipeline de entrenamiento en nuestro proyecto `nyc-taxi-time-prediction`\n",
    "\n",
    "- Vamos a crear una nueva rama `feat/training_orchestration`. \n",
    "- Vamos a crear un nuevo directorio `training pipeline`\n",
    "- crear un archivo llamado `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b026cb8548f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mlflow\n",
    "import pathlib\n",
    "import dagshub\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "def read_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df[\"duration\"] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_features(df_train: pd.DataFrame, df_val: pd.DataFrame):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "    df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "    categorical = [\"PU_DO\"]  #'PULocationID', 'DOLocationID']\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_train = df_train[\"duration\"].values\n",
    "    y_val = df_val[\"duration\"].values\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "\n",
    "def hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv):\n",
    "    \n",
    "    mlflow.xgboost.autolog()\n",
    "    \n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2024-01\")\n",
    "    \n",
    "    validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2024-02\")\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    def objective(params):\n",
    "        with mlflow.start_run(nested=True):\n",
    "             \n",
    "            # Tag model\n",
    "            mlflow.set_tag(\"model_family\", \"xgboost\")\n",
    "            \n",
    "            # Train model\n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=train,\n",
    "                num_boost_round=100,\n",
    "                evals=[(valid, 'validation')],\n",
    "                early_stopping_rounds=10\n",
    "            )\n",
    "            \n",
    "            # Predict in the val dataset\n",
    "            y_pred = booster.predict(valid)\n",
    "            \n",
    "            # Calculate metric\n",
    "            rmse = root_mean_squared_error(y_val, y_pred)\n",
    "            \n",
    "            # Log performance metric\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Xgboost Hyper-parameter Optimization\", nested=True):\n",
    "        search_space = {\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "            'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "            'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10,\n",
    "            trials=Trials()\n",
    "        )\n",
    "        best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "        best_params[\"seed\"] = 42\n",
    "        best_params[\"objective\"] = \"reg:squarederror\"\n",
    "        \n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "    return best_params\n",
    "\n",
    "\n",
    "def train_best_model(X_train, X_val, y_train, y_val, dv, best_params) -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "\n",
    "    with mlflow.start_run(\"Best model ever\"):\n",
    "        train = xgb.DMatrix(X_train, label=y_train)\n",
    "        valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        # Log a fit model instance\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "        \n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def main_flow(year: int, month_train: int, month_val: int) -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "    \n",
    "    train_path = f\"../data/green_tripdata_{year}-{month_train}.parquet\"\n",
    "    val_path = f\"../data/green_tripdata_{year}-{month_val}.parquet\"\n",
    "    \n",
    "    # MLflow settings\n",
    "    dagshub.init(url=\"https://dagshub.com/zapatacc/nyc-taxi-time-prediction\", mlflow=True)\n",
    "    \n",
    "    MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "    \n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(experiment_name=\"nyc-taxi-experiment-prefect\")\n",
    "\n",
    "    # Load\n",
    "    df_train = read_data(train_path)\n",
    "    df_val = read_data(val_path)\n",
    "\n",
    "    # Transform\n",
    "    X_train, X_val, y_train, y_val, dv = add_features(df_train, df_val)\n",
    "    \n",
    "    # Hyper-parameter Tunning\n",
    "    best_params = hyper_parameter_tunning(X_train, X_val, y_train, y_val, dv)\n",
    "    \n",
    "    # Train\n",
    "    train_best_model(X_train, X_val, y_train, y_val, dv, best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e547e097758c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
